{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP1Ie1rW4YaMo3Y8RN+wJxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicklausmillican/ISLR_R/blob/main/ISLR_R_Ch6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6"
      ],
      "metadata": {
        "id": "v06IlZa-LQKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceptual"
      ],
      "metadata": {
        "id": "VaDsnW3QCYIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "\n",
        "We perform best subset, forward stepwise, and backward stepwise selection on a single data set. For each approach, we obtain $p + 1$ models, containing $0, 1, 2,...,p$ predictors. Explain your answers:\n",
        "\n",
        "> (a) Which of the three models with $k$ predictors has the smallest *training* RSS?\n",
        "\n",
        "> (b) Which of the three models with $k$ predictors has the smallest *test* RSS?\n",
        "\n",
        "> (c) True or False:\n",
        "\n",
        "> > i. The predictors in the $k$-variable model identified by forward stepwise are a subset of the predictors in the ($k+1$)-variable model identified by forward stepwise selection.\n",
        "\n",
        "> > ii. The predictors in the $k$-variable model identified by backward stepwise are a subset of the predictors in the ($k + 1$)-variable model identified by backward stepwise selection.\n",
        "\n",
        "> > iii. The predictors in the $k$-variable model identified by backward stepwise are a subset of the predictors in the ($k + 1$)-variable model identified by forward stepwise selection.\n",
        "\n",
        "> > iv. The predictors in the $k$-variable model identified by forward stepwise are a subset of the predictors in the ($k+1$)-variable model identified by backward stepwise selection.\n",
        "\n",
        "> > v. The predictors in the $k$-variable model identified by best subset are a subset of the predictors in the ($k + 1$)-variable model identified by best subset selection."
      ],
      "metadata": {
        "id": "jDnvvJi7CcJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answers to a\n",
        "\n",
        "***Which of the three models with $k$ predictors has the smallest <u>training</u> RSS?***\n",
        "\n",
        "Each of the three methods progress, NOT by comparing RSS among models, but rather by comparing an estimate of fit to test data (e.g., AIC, BIC, $R_{adj}^2$).\n",
        "\n",
        "I think this means that any of the three methods may produce the lowest *training* RSS; this would be somewhat incidental since they are not trying to optimize for this."
      ],
      "metadata": {
        "id": "te_xnu53kEEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer to b\n",
        "\n",
        "***Which of the three models with $k$ predictors has the smallest <u>test</u> RSS?***\n",
        "\n",
        "Since only the *best-subset* method will examine all $k$-predictor models, it will discover the best-fit model.  Either stepwise method may also find the same model, but this is not guarenteed."
      ],
      "metadata": {
        "id": "6d4hEYu3k9ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer to b"
      ],
      "metadata": {
        "id": "bAiTdKR7pfVm"
      }
    }
  ]
}